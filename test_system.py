#!/usr/bin/env python3
"""
Simple working example of the DR Assistant system.
This demonstrates that everything is set up correctly.
"""

import torch
import numpy as np
from src.model import create_model, FocalLoss


def test_system():
    """Test the basic system functionality."""
    print("Diabetic Retinopathy Assistant - System Test")
    print("=" * 50)
    
    # Test 1: GPU availability
    print("1. Testing GPU availability...")
    if torch.cuda.is_available():
        print(f"   ‚úÖ CUDA available: {torch.cuda.get_device_name(0)}")
        print(f"   ‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        print("   ‚ùå CUDA not available")
        return False
    
    # Test 2: Model creation
    print("\n2. Testing model creation...")
    try:
        model = create_model()
        print(f"   ‚úÖ Model created successfully")
        print(f"   ‚úÖ Parameters: {sum(p.numel() for p in model.parameters()):,}")
    except Exception as e:
        print(f"   ‚ùå Model creation failed: {e}")
        return False
    
    # Test 3: Model on GPU (single image)
    print("\n3. Testing model on GPU (single image)...")
    try:
        model = model.cuda()
        model.eval()
        
        # Test with single image
        x = torch.randn(1, 3, 224, 224).cuda()
        with torch.no_grad():
            output = model(x)
        
        print(f"   ‚úÖ Model inference successful")
        print(f"   ‚úÖ Output shape: {output.shape}")
        print(f"   ‚úÖ Memory used: {torch.cuda.memory_allocated() / 1024**2:.1f} MB")
        
    except Exception as e:
        print(f"   ‚ùå GPU inference failed: {e}")
        return False
    
    # Test 4: Loss function
    print("\n4. Testing loss function...")
    try:
        criterion = FocalLoss()
        targets = torch.randint(0, 5, (1,)).cuda()
        loss = criterion(output, targets)
        print(f"   ‚úÖ Loss calculation successful: {loss.item():.4f}")
    except Exception as e:
        print(f"   ‚ùå Loss calculation failed: {e}")
        return False
    
    # Test 5: Batch processing (small batch)
    print("\n5. Testing small batch processing...")
    try:
        torch.cuda.empty_cache()  # Clear memory
        
        # Test with batch size 2
        x_batch = torch.randn(2, 3, 224, 224).cuda()
        targets_batch = torch.randint(0, 5, (2,)).cuda()
        
        with torch.no_grad():
            output_batch = model(x_batch)
            loss_batch = criterion(output_batch, targets_batch)
        
        print(f"   ‚úÖ Batch processing successful")
        print(f"   ‚úÖ Batch output shape: {output_batch.shape}")
        print(f"   ‚úÖ Batch loss: {loss_batch.item():.4f}")
        print(f"   ‚úÖ Peak memory: {torch.cuda.max_memory_allocated() / 1024**2:.1f} MB")
        
    except Exception as e:
        print(f"   ‚ùå Batch processing failed: {e}")
        return False
    
    print("\n" + "=" * 50)
    print("üéâ ALL TESTS PASSED!")
    print("=" * 50)
    print("\nYour system is ready for:")
    print("‚úÖ Training (with batch_size=2)")
    print("‚úÖ Inference")
    print("‚úÖ API serving")
    print("‚úÖ Web interface")
    
    print("\nNext steps:")
    print("1. Download datasets (see RUN_INSTRUCTIONS.md)")
    print("2. Run training: python src/train.py")
    print("3. Start API: python src/inference.py")
    print("4. Launch UI: streamlit run frontend/app.py")
    
    return True


if __name__ == "__main__":
    test_system()
