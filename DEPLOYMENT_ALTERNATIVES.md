# üöÄ Deployment Alternatives to Railway

## Quick Comparison

| Platform | Free Tier | Image Size Limit | Best For | Difficulty |
|----------|-----------|------------------|----------|------------|
| **Render.com** | ‚úÖ Yes | No strict limit | ML apps | ‚≠ê Easy |
| **Fly.io** | ‚úÖ Yes | 10 GB | Large apps | ‚≠ê‚≠ê Medium |
| **Google Cloud Run** | ‚úÖ Yes | 10 GB | Enterprise | ‚≠ê‚≠ê Medium |
| **Heroku** | ‚ùå Paid only | 500 MB | Simple apps | ‚≠ê Easy |
| **Vercel** | ‚úÖ Yes | 50 MB | Serverless | ‚≠ê‚≠ê Medium |
| **AWS Lambda** | ‚úÖ Yes | 10 GB | Serverless | ‚≠ê‚≠ê‚≠ê Hard |
| **Self-hosted** | ‚úÖ Free | Unlimited | Full control | ‚≠ê‚≠ê‚≠ê Hard |

---

## ‚úÖ Option 1: Render.com (Recommended - Easiest)

### Why Render?
- ‚úÖ **No strict image size limits** (perfect for ML apps!)
- ‚úÖ **Free tier available** (512 MB RAM)
- ‚úÖ **Similar to Railway** (easy migration)
- ‚úÖ **Auto-deploy from GitHub**
- ‚úÖ **Better for Python/ML apps**

### Steps:

1. **Go to Render.com**: https://render.com
2. **Sign up** with GitHub
3. **New** ‚Üí **Web Service**
4. **Connect repository**: `pathik1501/DR-assistant`
5. **Settings**:
   - **Name**: `dr-assistant-api`
   - **Environment**: `Python 3`
   - **Build Command**: `pip install -r requirements.txt`
   - **Start Command**: `python src/inference.py`
6. **Environment Variables**:
   - `OPENAI_API_KEY`: Your OpenAI key
   - `PORT`: Render uses `PORT` env var automatically
7. **Deploy!**

### Render Configuration File (Optional)

Create `render.yaml`:

```yaml
services:
  - type: web
    name: dr-assistant-api
    env: python
    buildCommand: pip install -r requirements.txt
    startCommand: python src/inference.py
    envVars:
      - key: OPENAI_API_KEY
        sync: false
    healthCheckPath: /health
```

---

## ‚úÖ Option 2: Fly.io (Good for Large Images)

### Why Fly.io?
- ‚úÖ **10 GB image size limit** (plenty of room!)
- ‚úÖ **Free tier**: 3 VMs free
- ‚úÖ **Global edge network**
- ‚úÖ **Great for ML apps**

### Steps:

1. **Install Fly CLI**:
   ```bash
   powershell -Command "iwr https://fly.io/install.ps1 -useb | iex"
   ```

2. **Login**:
   ```bash
   fly auth login
   ```

3. **Initialize**:
   ```bash
   fly launch
   ```

4. **Configure `fly.toml`**:
   ```toml
   app = "dr-assistant"
   primary_region = "iad"

   [build]
     dockerfile = "Dockerfile"

   [http_service]
     internal_port = 8080
     force_https = true
     auto_stop_machines = true
     auto_start_machines = true
     min_machines_running = 0

   [[vm]]
     memory_mb = 2048
     cpu_kind = "shared"
     cpus = 1
   ```

5. **Set secrets**:
   ```bash
   fly secrets set OPENAI_API_KEY=your-key-here
   ```

6. **Deploy**:
   ```bash
   fly deploy
   ```

---

## ‚úÖ Option 3: Google Cloud Run (Enterprise-Grade)

### Why Cloud Run?
- ‚úÖ **10 GB image size limit**
- ‚úÖ **Generous free tier** (2M requests/month)
- ‚úÖ **Auto-scaling**
- ‚úÖ **Pay per use** (very cheap)

### Steps:

1. **Install Google Cloud SDK**: https://cloud.google.com/sdk/docs/install

2. **Login**:
   ```bash
   gcloud auth login
   gcloud config set project YOUR_PROJECT_ID
   ```

3. **Build and deploy**:
   ```bash
   gcloud builds submit --tag gcr.io/YOUR_PROJECT/dr-assistant
   gcloud run deploy dr-assistant \
     --image gcr.io/YOUR_PROJECT/dr-assistant \
     --platform managed \
     --region us-central1 \
     --allow-unauthenticated \
     --set-env-vars OPENAI_API_KEY=your-key-here
   ```

---

## ‚úÖ Option 4: Simple Python Hosting (PythonAnywhere, Replit)

### PythonAnywhere

**Pros:**
- ‚úÖ Simple Python hosting
- ‚úÖ Free tier available
- ‚úÖ No Docker needed

**Steps:**
1. Go to https://www.pythonanywhere.com
2. Create account
3. Upload files via web interface
4. Run: `python src/inference.py`
5. Use their web app feature

### Replit

**Pros:**
- ‚úÖ Free tier
- ‚úÖ Easy setup
- ‚úÖ Built-in editor

**Steps:**
1. Go to https://replit.com
2. Import from GitHub
3. Install dependencies
4. Run: `python src/inference.py`
5. Use Replit's web hosting

---

## ‚úÖ Option 5: VPS/Cloud Server (Full Control)

### Providers:
- **DigitalOcean**: $4/month (Droplet)
- **Linode**: $5/month
- **Vultr**: $2.50/month
- **AWS EC2**: Free tier (t2.micro)
- **Google Cloud Compute**: Free tier (f1-micro)

### Steps:

1. **Create VM** (Ubuntu 22.04)
2. **SSH into server**:
   ```bash
   ssh user@your-server-ip
   ```

3. **Install dependencies**:
   ```bash
   sudo apt update
   sudo apt install python3-pip python3-venv git
   ```

4. **Clone repo**:
   ```bash
   git clone https://github.com/pathik1501/DR-assistant.git
   cd DR-assistant
   ```

5. **Setup virtual environment**:
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```

6. **Set environment variables**:
   ```bash
   export OPENAI_API_KEY=your-key-here
   export PORT=8080
   ```

7. **Run with systemd** (auto-start):
   ```bash
   sudo nano /etc/systemd/system/dr-assistant.service
   ```

   ```ini
   [Unit]
   Description=DR Assistant API
   After=network.target

   [Service]
   User=your-user
   WorkingDirectory=/home/your-user/DR-assistant
   Environment="OPENAI_API_KEY=your-key-here"
   Environment="PORT=8080"
   ExecStart=/home/your-user/DR-assistant/venv/bin/python src/inference.py
   Restart=always

   [Install]
   WantedBy=multi-user.target
   ```

8. **Start service**:
   ```bash
   sudo systemctl enable dr-assistant
   sudo systemctl start dr-assistant
   ```

9. **Setup Nginx** (reverse proxy):
   ```bash
   sudo apt install nginx
   sudo nano /etc/nginx/sites-available/dr-assistant
   ```

   ```nginx
   server {
       listen 80;
       server_name your-domain.com;

       location / {
           proxy_pass http://localhost:8080;
           proxy_set_header Host $host;
           proxy_set_header X-Real-IP $remote_addr;
       }
   }
   ```

   ```bash
   sudo ln -s /etc/nginx/sites-available/dr-assistant /etc/nginx/sites-enabled/
   sudo nginx -t
   sudo systemctl restart nginx
   ```

---

## ‚úÖ Option 6: Docker + Any Cloud Provider

### Use the Dockerfile we already have:

1. **Build image locally**:
   ```bash
   docker build -t dr-assistant .
   ```

2. **Run locally**:
   ```bash
   docker run -p 8080:8080 -e OPENAI_API_KEY=your-key dr-assistant
   ```

3. **Push to Docker Hub**:
   ```bash
   docker tag dr-assistant yourusername/dr-assistant
   docker push yourusername/dr-assistant
   ```

4. **Deploy to any cloud** that supports Docker:
   - AWS ECS
   - Google Cloud Run
   - Azure Container Instances
   - DigitalOcean App Platform
   - Fly.io

---

## üéØ My Recommendation

### For Easiest Deployment: **Render.com**
- ‚úÖ No image size issues
- ‚úÖ Similar to Railway
- ‚úÖ Free tier
- ‚úÖ Auto-deploy from GitHub

### For Best Performance: **Fly.io**
- ‚úÖ 10 GB limit (plenty of room)
- ‚úÖ Global edge network
- ‚úÖ Free tier available

### For Full Control: **VPS (DigitalOcean/Linode)**
- ‚úÖ Complete control
- ‚úÖ No restrictions
- ‚úÖ ~$5/month
- ‚úÖ Learn Linux/sysadmin skills

---

## üìã Quick Start: Render.com (Recommended)

1. **Go to**: https://render.com
2. **Sign up** with GitHub
3. **New** ‚Üí **Web Service**
4. **Select repo**: `pathik1501/DR-assistant`
5. **Settings**:
   - Build: `pip install -r requirements.txt`
   - Start: `python src/inference.py`
6. **Environment**: `OPENAI_API_KEY=your-key`
7. **Deploy!**

**That's it!** No image size issues! üéâ

---

## üîÑ Migration from Railway

If you want to switch:

1. **Keep your code** (no changes needed!)
2. **Update deployment platform**
3. **Update environment variables**
4. **Update frontend API URL** (if needed)

**Your code will work on any platform!**

---

**Want me to help set up any of these?** Let me know which one you prefer! üöÄ

